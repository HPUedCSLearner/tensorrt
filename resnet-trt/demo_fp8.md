## **ğŸš€ åœ¨ TensorRT ä¸­ä½¿ç”¨ FP8 è¿›è¡Œæ¨ç†**

RTX 4060  **æ”¯æŒ FP8** ï¼ˆfloat8ï¼‰åŠ é€Ÿï¼Œå› æ­¤ä½ å¯ä»¥åœ¨ **TensorRT 9+** ç‰ˆæœ¬ä¸­ä½¿ç”¨ FP8 è¿›è¡Œæ¨ç†ã€‚

---

## **ğŸ”¥ FP8 æ”¯æŒçš„ TensorRT ç‰ˆæœ¬**

* **TensorRT 9 åŠä»¥ä¸Š** ï¼šå®˜æ–¹æ”¯æŒ FP8ã€‚
* **TensorRT 8 åŠä»¥ä¸‹** ï¼šä¸æ”¯æŒ FP8ï¼Œæœ€å¤šæ”¯æŒåˆ° FP16ï¼ˆå¯ä»¥ä½¿ç”¨ INT8ï¼Œä½†æ²¡æœ‰ FP8 è®¡ç®—å•å…ƒï¼‰ã€‚

ä½ çš„  **RTX 4060ï¼ˆAda Lovelace æ¶æ„ï¼‰æ”¯æŒ FP8** ï¼Œä½†ä½ éœ€è¦ï¼š

1. **ç¡®ä¿ TensorRT 9 å·²å®‰è£…** ï¼ˆ`trtexec --version` æ£€æŸ¥ï¼‰ã€‚
2. **ONNX æ¨¡å‹å¿…é¡»è½¬æ¢ä¸º FP8** ï¼ˆå¯ä»¥ä½¿ç”¨ `torch.float8_e4m3fn` é‡åŒ–ï¼‰ã€‚

---

## **âœ… 1. å…ˆè½¬æ¢ ResNet-101 ONNX ä¸º FP8**

### **æ–¹å¼ 1ï¼šä½¿ç”¨ PyTorch é‡åŒ– ResNet**

```python
import torch
import torchvision.models as models

# åŠ è½½ ResNet-101 é¢„è®­ç»ƒæ¨¡å‹
model = models.resnet101(pretrained=True)
model.eval()

# è½¬æ¢æƒé‡ä¸º FP8
for param in model.parameters():
    param.data = param.data.to(torch.float8_e4m3fn)  # e4m3 æ˜¯ FP8 æ ¼å¼ä¹‹ä¸€

# è½¬æ¢ä¸º ONNX
dummy_input = torch.randn(1, 3, 224, 224).to(torch.float8_e4m3fn)
torch.onnx.export(model, dummy_input, "resnet101_fp8.onnx", opset_version=17)
```

* `float8_e4m3fn`ï¼šFP8 æ ¼å¼ï¼ˆæ¯” FP16 æ›´ä½ç²¾åº¦ï¼Œé€‚ç”¨äº Transformerï¼‰ã€‚
* `opset_version=17`ï¼šONNX 17 ç‰ˆæœ¬æ”¯æŒ FP8ã€‚

---

## **âœ… 2. ä½¿ç”¨ TensorRT 9 è½¬æ¢ ONNX ä¸º FP8**

```python
import tensorrt as trt

TRT_LOGGER = trt.Logger(trt.Logger.WARNING)

def build_fp8_engine(onnx_path, trt_path):
    builder = trt.Builder(TRT_LOGGER)
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    parser = trt.OnnxParser(network, TRT_LOGGER)

    with open(onnx_path, "rb") as f:
        if not parser.parse(f.read()):
            for i in range(parser.num_errors):
                print(parser.get_error(i))
            raise RuntimeError("ONNX è§£æå¤±è´¥")

    config = builder.create_builder_config()
    config.set_flag(trt.BuilderFlag.FP8)  # âœ… å¯ç”¨ FP8
    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 2 << 30)  # 2GB å†…å­˜

    # åˆ›å»ºä¼˜åŒ– profile
    profile = builder.create_optimization_profile()
    input_tensor = network.get_input(0)
    profile.set_shape(input_tensor.name, (1, 3, 224, 224), (8, 3, 224, 224), (16, 3, 224, 224))
    config.add_optimization_profile(profile)

    # æ„å»º TensorRT å¼•æ“
    serialized_engine = builder.build_serialized_network(network, config)
    if serialized_engine is None:
        raise RuntimeError("æ„å»º TensorRT å¼•æ“å¤±è´¥")

    with open(trt_path, "wb") as f:
        f.write(serialized_engine)
    print("FP8 TensorRT Engine å·²ä¿å­˜:", trt_path)

build_fp8_engine("resnet101_fp8.onnx", "resnet101_fp8.trt")
```

---

## **âœ… 3. è¿è¡Œ FP8 æ¨ç†**

```python
import numpy as np
import pycuda.driver as cuda
import pycuda.autoinit
import tensorrt as trt

TRT_LOGGER = trt.Logger(trt.Logger.WARNING)

def load_engine(trt_path):
    with open(trt_path, "rb") as f, trt.Runtime(TRT_LOGGER) as runtime:
        return runtime.deserialize_cuda_engine(f.read())

engine = load_engine("resnet101_fp8.trt")
context = engine.create_execution_context()

# åˆ†é… GPU å†…å­˜
input_shape = (1, 3, 224, 224)
d_input = cuda.mem_alloc(int(np.prod(input_shape)) * np.float8_e4m3fn().nbytes)
d_output = cuda.mem_alloc(int(np.prod((1, 1000))) * np.float8_e4m3fn().nbytes)
stream = cuda.Stream()

# ç”Ÿæˆéšæœºè¾“å…¥æ•°æ®
input_data = np.random.randn(*input_shape).astype(np.float8_e4m3fn)

# å¤åˆ¶æ•°æ®åˆ° GPU
cuda.memcpy_htod_async(d_input, input_data, stream)

# æ‰§è¡Œ FP8 æ¨ç†
context.execute_v2([int(d_input), int(d_output)])

# å¤åˆ¶è¾“å‡ºå› CPU
output_data = np.empty((1, 1000), dtype=np.float8_e4m3fn)
cuda.memcpy_dtoh_async(output_data, d_output, stream)
stream.synchronize()

print("FP8 TensorRT æ¨ç†å®Œæˆï¼Œè¾“å‡º shape:", output_data.shape)
```

---

## **ğŸš€ 4. è¿è¡Œ FP8 TensorRT**

```bash
python convert_to_trt.py  # è½¬æ¢ FP8
python infer_trt.py        # è¿è¡Œ FP8 æ¨ç†
```

---

## **ğŸ”¥ æ€»ç»“**

1. **ONNX è½¬æ¢** ï¼š

* ä½¿ç”¨ **PyTorch é‡åŒ–** ResNet-101ï¼Œè½¬æ¢ä¸º  **FP8 ONNX** ã€‚

1. **TensorRT ç¼–è¯‘** ï¼š

* ä½¿ç”¨ `config.set_flag(trt.BuilderFlag.FP8)` ç¼–è¯‘ FP8 TensorRT å¼•æ“ã€‚

1. **æ¨ç†** ï¼š

* ç¡®ä¿è¾“å…¥è¾“å‡º **dtype ä¸º FP8** (`np.float8_e4m3fn`)ã€‚

ä½ å¯ä»¥è¯•è¯•ï¼Œçœ‹çœ‹ FP8 èƒ½å¦æˆåŠŸè¿è¡Œï¼Œé‡åˆ°é—®é¢˜éšæ—¶é—®æˆ‘ï¼ğŸ’ªğŸ”¥
